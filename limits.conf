# Obviamente, temos comentários ;)
# A primeira linha deve ter o número máximo de requests em paralelo:
32

# A terceira linha é o limite de subdiretórios (0 == sem limite):
64
# (para a profundidade de sub-diretórios,
# pega no máximo 64*64=4096 URLs por host)

# E agora, as exclusões. São expressões em Perl que devem retornar
# valor != 0 para que a URL processada não seja incluida no Tasklist.
# Ah, para maior diversão, temos acesso ao objeto 'URI': $uri
# Assim, por exemplo, $uri->host é o domínio da URL ;)
# Exemplo:
$uri->host ne 'sysd.org'	# restringe o crawler apenas nesse servidor

#!($uri->host =~ /\.br$/i)	# apenas os domínios .br
#scalar @{[($uri->path_segments)]} > 3	# só se 'aprofunda' até http://host/dir/


# Domínios inúteis
$uri->host =~ /bl[io]+g/i
$uri->host =~ /f(oto)?lo+g/i
$uri->host =~ /logger/i
$uri->host =~ /uolkut/i
$uri->host =~ /webogger/i
$uri->host =~ /\bbuscaletras\.com\.br$/i
$uri->host =~ /\bcomprar-\w+\.com\.br$/i
$uri->host =~ /\bcomprar\.art\.br$/i
$uri->host =~ /\bfotogold\.com\.br$/i
$uri->host =~ /\bgiga(fotos?|musica)\.com\.br$/i
$uri->host =~ /\bglobolog\.com\.br$/i
$uri->host =~ /\bhyperfotos\.com\.br$/i
$uri->host =~ /\bletras\.mus(ica\.com)?\.br$/i
$uri->host =~ /\bletras\.terra\.com\.br$/i
$uri->host =~ /\blogme\.com\.br$/i
$uri->host =~ /\bmusicaseletras\.com\.br$/i
$uri->host =~ /\bomeu\.com\.br$/i

# Domínios lerdos
$uri->host =~ /\bacessetudo\.com\.br$/i
$uri->host =~ /\bbuscavenda\.com\.br$/i
$uri->host =~ /\bmeache\.com\.br$/i
$uri->host =~ /\bradarweb\.com\.br$/i
